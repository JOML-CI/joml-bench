# How to run

With JAVA_HOME and PATH pointing to a Panama vectorIntrinsics build, run:

```
./mvnw package && java --add-modules jdk.incubator.vector -jar target/bench.jar
```

Without having a local Panama vectorIntrinsics build, run:
```
./ci.sh
```
This will shallow-clone the [GitHub mirror of the Panama vectorIntrinsics branch](https://github.com/openjdk/panama-vector/tree/vectorIntrinsics), build the JDK and execute the benchmarks using it. Make sure your system fulfills the [OpenJDK build requirements](https://github.com/openjdk/panama-vector/blob/vectorIntrinsics/doc/building.md). See the section "Clean Ubuntu Setup" below for a clean Ubuntu setup.
The space requirements for such a cloned and fully built JDK is ~5.6GB, which will reside inside of the panama-vector directory.
In addition, the hsdis utility library is built and installed into the JDK's lib directory.

## Clean Ubuntu Setup (tested on Ubuntu 20.04)

```
sudo apt install -y libasound2-dev \
                    libfontconfig1-dev \
                    libcups2-dev \
                    libx11-dev \
                    libxext-dev \
                    libxrender-dev \
                    libxrandr-dev \
                    libxtst-dev \
                    libxt-dev \
                    git \
                    zip \
                    unzip \
                    automake \
                    autoconf \
                    build-essential
```

## Seeing the disassembly

In order to see the x86 code generated by the JIT compiler for all methods, run:
```
java --add-modules jdk.incubator.vector -XX:+UnlockDiagnosticVMOptions -XX:CompileCommand=print,*Matrix*.* -cp target/bench.jar bench.C2
```
The x86 code is then printed to stdout. This requires the hsdis utility library available in the $JAVA_HOME/lib directory, as is provided by `./ci.sh`.

# Results

## Intel Xeon E-2176M
### With -Djdk.incubator.vector.VECTOR_ACCESS_OOB_CHECK=0
```
Benchmark                      Mode  Cnt   Score   Error  Units
Bench.Matrix4f_invert          avgt   30  23.865 ± 0.268  ns/op
Bench.Matrix4f_storePutBB      avgt   30   6.982 ± 0.010  ns/op
Bench.Matrix4f_storePutFB      avgt   30   4.408 ± 0.011  ns/op
Bench.Matrix4f_storeU          avgt   30   2.535 ± 0.006  ns/op
Bench.Matrix4fn_mulAVX         avgt   30  11.650 ± 0.020  ns/op
Bench.Matrix4fn_mulSSE         avgt   30  14.461 ± 0.797  ns/op
Bench.Matrix4fn_noop           avgt   30   8.726 ± 0.012  ns/op
Bench.Matrix4fvArr_invert128   avgt   30  91.663 ± 0.512  ns/op
Bench.Matrix4fvArr_storePutFB  avgt   30   4.770 ± 0.004  ns/op
Bench.Matrix4fvArr_storeU      avgt   30   2.789 ± 0.003  ns/op
Bench.Matrix4fvArr_storeV256   avgt   30   1.818 ± 0.047  ns/op
Bench.Matrix4fvArr_storeV512   avgt   30  33.289 ± 0.649  ns/op
Bench.mul128LoopArr            avgt   30   8.030 ± 0.254  ns/op
Bench.mul128LoopBB             avgt   30   7.846 ± 0.034  ns/op
Bench.mul128UnrolledArr        avgt   30   8.591 ± 0.016  ns/op
Bench.mul128UnrolledBB         avgt   30  10.092 ± 0.092  ns/op
Bench.mul256Arr                avgt   30   7.477 ± 0.008  ns/op
Bench.mul256BB                 avgt   30   7.389 ± 0.184  ns/op
Bench.mulAffineScalarFma       avgt   30  12.701 ± 0.617  ns/op
Bench.mulScalar                avgt   30  19.308 ± 0.554  ns/op
Bench.mulScalarFma             avgt   30  15.267 ± 0.539  ns/op
```
