# How to run

With JAVA_HOME and PATH pointing to a Panama vectorIntrinsics build, run:

```
./mvnw package && java --add-modules jdk.incubator.vector -jar target/bench.jar
```

Without having a local Panama vectorIntrinsics build, run:
```
./ci.sh
```
This will shallow-clone the [GitHub mirror of the Panama vectorIntrinsics branch](https://github.com/openjdk/panama-vector/tree/vectorIntrinsics), build the JDK and execute the benchmarks using it. Make sure your system fulfills the [OpenJDK build requirements](https://github.com/openjdk/panama-vector/blob/vectorIntrinsics/doc/building.md). See the section "Clean Ubuntu Setup" below for a clean Ubuntu setup.
The space requirements for such a cloned and fully built JDK is ~5.6GB, which will reside inside of the panama-vector directory.
In addition, the hsdis utility library is built and installed into the JDK's lib directory.

## Clean Ubuntu Setup (tested on Ubuntu 20.04)

```
sudo apt install -y libasound2-dev \
                    libfontconfig1-dev \
                    libcups2-dev \
                    libx11-dev \
                    libxext-dev \
                    libxrender-dev \
                    libxrandr-dev \
                    libxtst-dev \
                    libxt-dev \
                    git \
                    zip \
                    unzip \
                    automake \
                    autoconf \
                    build-essential
```

## Seeing the disassembly

In order to see the x86 code generated by the JIT compiler for all methods, run:
```
java --add-modules jdk.incubator.vector -XX:+UnlockDiagnosticVMOptions -XX:CompileCommand=print,*Matrix*.* -cp target/bench.jar bench.C2
```
The x86 code is then printed to stdout. This requires the hsdis utility library available in the $JAVA_HOME/lib directory, as is provided by `./ci.sh`.

# Results

## Intel Xeon E-2176M
### With -Djdk.incubator.vector.VECTOR_ACCESS_OOB_CHECK=0
```
Benchmark                      Mode  Cnt   Score   Error  Units
Bench.Matrix4f_invert          avgt   50  22.498 ± 0.080  ns/op
Bench.Matrix4f_storePutBB      avgt   50   7.028 ± 0.018  ns/op
Bench.Matrix4f_storePutFB      avgt   50  69.308 ± 0.135  ns/op
Bench.Matrix4f_storeU          avgt   50   2.514 ± 0.008  ns/op
Bench.Matrix4f_transpose       avgt   50   3.761 ± 0.002  ns/op
Bench.Matrix4fn_mulAVX         avgt   50  11.656 ± 0.024  ns/op
Bench.Matrix4fn_mulSSE         avgt   50  11.818 ± 0.005  ns/op
Bench.Matrix4fn_noop           avgt   50   8.550 ± 0.007  ns/op
Bench.Matrix4fvArr_invert128   avgt   50  93.214 ± 0.839  ns/op
Bench.Matrix4fvArr_storePutFB  avgt   50   5.051 ± 0.004  ns/op
Bench.Matrix4fvArr_storeU      avgt   50   2.753 ± 0.002  ns/op
Bench.Matrix4fvArr_storeV256   avgt   50   1.666 ± 0.025  ns/op
Bench.Matrix4fvArr_storeV512   avgt   50  33.620 ± 0.393  ns/op
Bench.Matrix4fvArr_transpose   avgt   50  73.398 ± 0.693  ns/op
Bench.mul128LoopArr            avgt   50   8.016 ± 0.195  ns/op
Bench.mul128LoopBB             avgt   50   8.518 ± 0.009  ns/op
Bench.mul128UnrolledArr        avgt   50   8.764 ± 0.055  ns/op
Bench.mul128UnrolledBB         avgt   50   9.332 ± 0.100  ns/op
Bench.mul256Arr                avgt   50   7.546 ± 0.052  ns/op
Bench.mul256BB                 avgt   50   8.214 ± 0.014  ns/op
Bench.mulAffineScalarFma       avgt   50  10.839 ± 0.051  ns/op
Bench.mulScalar                avgt   50  18.740 ± 0.021  ns/op
Bench.mulScalarFma             avgt   50  14.109 ± 0.015  ns/op
```
