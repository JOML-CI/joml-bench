# How to run

With JAVA_HOME and PATH pointing to a Panama vectorIntrinsics build, run:

```
./mvnw package && java --add-modules jdk.incubator.vector -jar target/bench.jar
```

Without having a local Panama vectorIntrinsics build, run:
```
./ci.sh
```
This will shallow-clone the [GitHub mirror of the Panama vectorIntrinsics branch](https://github.com/openjdk/panama-vector/tree/vectorIntrinsics), build the JDK and execute the benchmarks using it. Make sure your system fulfills the [OpenJDK build requirements](https://github.com/openjdk/panama-vector/blob/vectorIntrinsics/doc/building.md). See the section "Clean Ubuntu Setup" below for a clean Ubuntu setup.
The space requirements for such a cloned and fully built JDK is ~5.6GB, which will reside inside of the panama-vector directory.
In addition, the hsdis utility library is built and installed into the JDK's lib directory.

## Clean Ubuntu Setup (tested on Ubuntu 20.04)

```
sudo apt install -y libasound2-dev \
                    libfontconfig1-dev \
                    libcups2-dev \
                    libx11-dev \
                    libxext-dev \
                    libxrender-dev \
                    libxrandr-dev \
                    libxtst-dev \
                    libxt-dev \
                    git \
                    zip \
                    unzip \
                    automake \
                    autoconf \
                    build-essential
```

## Seeing the disassembly

In order to see the x86 code generated by the JIT compiler for all methods, run:
```
java --add-modules jdk.incubator.vector -XX:+UnlockDiagnosticVMOptions -XX:CompileCommand=print,*Matrix*.* -cp target/bench.jar bench.C2
```
The x86 code is then printed to stdout. This requires the hsdis utility library available in the $JAVA_HOME/lib directory, as is provided by `./ci.sh`.

# Results

## Intel Xeon E-2176M
### With -Djdk.incubator.vector.VECTOR_ACCESS_OOB_CHECK=0
```
Benchmark                      Mode  Cnt   Score   Error  Units
Bench.Matrix4f_invert          avgt    5  23.694 ± 3.175  ns/op
Bench.Matrix4f_storePutBB      avgt    5   7.284 ± 0.043  ns/op
Bench.Matrix4f_storePutFB      avgt    5   5.389 ± 0.281  ns/op
Bench.Matrix4f_storeU          avgt    5   3.058 ± 0.039  ns/op
Bench.Matrix4f_transpose       avgt    5   4.467 ± 1.334  ns/op
Bench.Matrix4fn_mulAVX         avgt    5  11.730 ± 0.308  ns/op
Bench.Matrix4fn_mulSSE         avgt    5  11.566 ± 0.492  ns/op
Bench.Matrix4fn_noop           avgt    5   9.290 ± 0.832  ns/op
Bench.Matrix4fvArr_invert128   avgt    5  93.220 ± 6.345  ns/op
Bench.Matrix4fvArr_storePutFB  avgt    5   5.138 ± 0.117  ns/op
Bench.Matrix4fvArr_storeU      avgt    5   3.400 ± 0.105  ns/op
Bench.Matrix4fvArr_storeV256   avgt    5   1.763 ± 0.060  ns/op
Bench.Matrix4fvArr_storeV512   avgt    5  34.234 ± 5.885  ns/op
Bench.Matrix4fvArr_transpose   avgt    5  73.953 ± 0.529  ns/op
Bench.mul128LoopArr            avgt    5   8.328 ± 0.367  ns/op
Bench.mul128LoopBB             avgt    5   8.463 ± 0.036  ns/op
Bench.mul128UnrolledArr        avgt    5   8.655 ± 0.211  ns/op
Bench.mul128UnrolledBB         avgt    5  10.150 ± 0.442  ns/op
Bench.mul256Arr                avgt    5   8.203 ± 1.434  ns/op
Bench.mul256BB                 avgt    5   7.559 ± 0.906  ns/op
Bench.mulAffineScalarFma       avgt    5  11.682 ± 1.950  ns/op
Bench.mulScalar                avgt    5  17.988 ± 1.929  ns/op
Bench.mulScalarFma             avgt    5  14.134 ± 0.835  ns/op
```
